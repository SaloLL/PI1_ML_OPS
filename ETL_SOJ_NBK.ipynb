{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=center><h1>Individual Project Nº1</h1>\n",
    "<h4>Salomón Orozco Jaramillo</h4>\n",
    "<h4>ETL (Extract, Transform, Load)</h4>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Libs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing necessary libraries\n",
    "import ast  # For working with Python literal syntax\n",
    "import json  # For working with JSON files\n",
    "import pandas as pd  # For data manipulation\n",
    "import nltk  # Natural Language Toolkit\n",
    "import re # Regular Expression library\n",
    "import nltk # Use the nltk library with vader_lexicon and sentiment to transform reviews into sentiment scores\n",
    "nltk.download('vader_lexicon') # Download  VADER lexicon from NLTK\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer # Initiate  the sentiment analyzer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## australian_users_items.json etl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a list for the items\n",
    "review = []\n",
    "# Opening json\n",
    "with open('datasets/australian_users_items.json', 'r', encoding='utf-8') as usersItemJson:\n",
    "    for line in usersItemJson:\n",
    "        # Append json items to the list\n",
    "        review.append(ast.literal_eval(line))\n",
    "# Close the json file explicitly\n",
    "usersItemJson.close()\n",
    "# Creating a dataframe\n",
    "df_user_items = pd.DataFrame(review)\n",
    "# Viewing the dataframe\n",
    "df_user_items"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Desempaquetar la columna 'Items'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unpacking the 'Items' column\n",
    "data_user_temp1 = df_user_items.explode(['items'])\n",
    "# Normalizing JSON data in the 'items' column\n",
    "data_user_temp2 = pd.json_normalize(data_user_temp1['items']).set_index(data_user_temp1['items'].index)\n",
    "# Concatenating normalized data with the original DataFrame\n",
    "data_user_temp3 = pd.concat([data_user_temp2, data_user_temp1], axis=1)\n",
    "# Updating the original DataFrame with the concatenated data\n",
    "df_user_items = data_user_temp3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the 'items' column from the DataFrame\n",
    "df_user_items = df_user_items.drop('items', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View DataFrame\n",
    "df_user_items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the 'item_id' content data for a specific user ('76561198329548331')\n",
    "df_user_items.loc[df_user_items['user_id'] == '76561198329548331']\n",
    "\n",
    "#df_user_items['steam_id'].info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the number of null values per column in df_user_items\n",
    "null_per_col = df_user_items.isnull().sum()\n",
    "\n",
    "#null_per_col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove columns that are not needed\n",
    "df_user_items = df_user_items.drop('user_url', axis=1)\n",
    "df_user_items = df_user_items.drop('items_count', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View DataFrame\n",
    "\n",
    "df_user_items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display information about df_user_items\n",
    "df_user_items.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find NaN values and drop corresponding rows for specific columns\n",
    "df_user_items = df_user_items.dropna(subset=['item_id'])\n",
    "df_user_items = df_user_items.dropna(subset=['item_name'])\n",
    "df_user_items = df_user_items.dropna(subset=['playtime_forever'])\n",
    "df_user_items = df_user_items.dropna(subset=['playtime_2weeks'])\n",
    "df_user_items = df_user_items.dropna(subset=['steam_id'])\n",
    "df_user_items = df_user_items.dropna(subset=['user_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary mapping old column names to new column names\n",
    "column_mapping = {\n",
    "    'user_id': 'User_Id',\n",
    "    'item_id': 'Item_Id',\n",
    "    'playtime_forever': 'Playtime_Forever',\n",
    "    'item_name': 'Item_Name',\n",
    "    'steam_id': 'Steam_Id',\n",
    "    'playtime_2weeks': 'Playtime_2Weeks'\n",
    "}\n",
    "\n",
    "# Rename columns using the dictionary\n",
    "df_user_items = df_user_items.rename(columns=column_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View Dataframe\n",
    "df_user_items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get DataFrame info\n",
    "df_user_items.info()\n",
    "duplicates = df_user_items.duplicated()\n",
    "print(duplicates.sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export Data Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the DataFrame to a CSV file\n",
    "df_user_items.to_csv('CSV/user_items.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the DataFrame to a compressed Parquet file\n",
    "df_user_items.to_parquet('GZIP/user_items.gzip', compression='gzip')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## output_steam_games.json etl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List to store JSON objects\n",
    "games = []\n",
    "# Read 'output_steam_games.json' line by line and load as JSON\n",
    "with open('datasets/output_steam_games.json', 'r', encoding='utf-8') as f:\n",
    "    for line in f.readlines():\n",
    "        games.append(json.loads(line))\n",
    "# Create a DataFrame from the list of JSON objects\n",
    "df_steam_games = pd.DataFrame(games)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View DataFrame\n",
    "df_steam_games"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary mapping old column names to new column names\n",
    "column_mapping = {\n",
    "    'publisher': 'Publisher',\n",
    "    'genres': 'Genres',\n",
    "    'app_name': 'App_Name',\n",
    "    'title': 'Title',\n",
    "    'url': 'Url',\n",
    "    'release_date': 'Release_Date',\n",
    "    'tags': 'Tags',\n",
    "    'reviews_url': 'Reviews_Url',\n",
    "    'specs': 'Specs',\n",
    "    'price': 'Price',\n",
    "    'early_access': 'Early_Access',\n",
    "    'id': 'Id',\n",
    "    'developer': 'Developer'\n",
    "}\n",
    "# Rename columns using the dictionary\n",
    "df_steam_games = df_steam_games.rename(columns=column_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View new column names\n",
    "df_steam_games.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_col(col):\n",
    "    \"\"\"\n",
    "    Normalize a developer name by removing non-alphabetic characters,\n",
    "    converting to lowercase, and removing extra whitespaces.\n",
    "    \"\"\"\n",
    "    if isinstance(col, str):  # Verify if it is a string\n",
    "        cleaned_name = re.sub(r'[^a-zA-Z\\s]', '', col)\n",
    "        new_name = re.sub(r'\\s+', ' ', cleaned_name.lower().strip())\n",
    "        return new_name\n",
    "    else:\n",
    "        return col\n",
    "\n",
    "# Apply the normalize_col function to the 'Publisher' column\n",
    "df_steam_games['Publisher'] = df_steam_games['Publisher'].apply(normalize_col)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the 'Url' column\n",
    "df_steam_games.drop('Url', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_steam_games"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to convert float to string\n",
    "def float_to_string(value):\n",
    "    \"\"\"\n",
    "    Convert a float to string. If the value is not a float, return it unchanged.\n",
    "    \"\"\"\n",
    "    if isinstance(value, float):\n",
    "        return str(value)\n",
    "    return value\n",
    "# Apply the float_to_str function to the 'Publisher' column\n",
    "df_steam_games['Publisher'] = df_steam_games['Publisher'].apply(float_to_string)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Capitalize the first letter of each word in the 'Publisher' column\n",
    "df_steam_games['Publisher'] = df_steam_games['Publisher'].str.title()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count Null values in 'Publisher'\n",
    "nullPublisher = df_steam_games['Publisher'].isnull().sum()\n",
    "print(\"Null values in 'Publisher':\",nullPublisher)\n",
    "\n",
    "# Count NaN values in 'Publisher'\n",
    "nans_as_strings = (df_steam_games['Publisher'].str.lower() == 'nan').sum()\n",
    "# Print the number of NaN values represented as strings in 'Publisher'\n",
    "print(\"NaN values in 'Publisher':\", nans_as_strings)\n",
    "print('--------')\n",
    "# Count Null values in 'Publisher'\n",
    "nullPublisher = df_steam_games['Genres'].isnull().sum()\n",
    "print(\"Null values in 'Genres':\",nullPublisher)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check Genres content\n",
    "print(df_steam_games['Genres'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the values in the 'Genres' column to a comma-separated string\n",
    "df_steam_games['Genres'] = df_steam_games['Genres'].astype(str).apply(lambda x: ', '.join(filter(None, x.split(','))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_steam_games"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove rows with NaN values in 'Genres'\n",
    "df_steam_games.dropna(subset=['Genres'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_steam_games['Genres']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_steam_games['Specs']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count null values in 'Specs'\n",
    "nullSpecs = df_steam_games['Specs'].isnull().sum()\n",
    "# Print the number of null values in 'Specs'\n",
    "print(\"Null values in 'Specs':\", nullSpecs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove rows with NaN values in 'Specs'\n",
    "df_steam_games.dropna(subset=['Specs'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract 'Specs' specifications\n",
    "df_steam_games['Specs'] = df_steam_games['Specs'].apply(lambda x: ', '.join(filter(None, x)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_steam_games"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count null values in 'title'\n",
    "null_count = df_steam_games['Title'].isnull().sum()\n",
    "# Print the number of null values in 'title'\n",
    "print(f\"Null values in 'Title': {null_count}\")\n",
    "# Count null app_name in 'App_name'\n",
    "null_count = df_steam_games['App_Name'].isnull().sum()\n",
    "# Print the number of null values in 'title'\n",
    "print(f\"Null values in 'App_Name': {null_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop Title column\n",
    "df_steam_games = df_steam_games.drop('Title', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove Na in App_Name\n",
    "df_steam_games.dropna(subset=['App_Name'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_steam_games"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize App_Name column names\n",
    "df_steam_games['App_Name'] = df_steam_games['App_Name'].apply(normalize_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Capitalize App name column\n",
    "df_steam_games['App_Name'] = df_steam_games['App_Name'].str.title()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove columns 'reviews_url' and 'tags'\n",
    "remove_columns = ['Reviews_Url', 'Tags']\n",
    "df_steam_games = df_steam_games.drop(columns=remove_columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View DataFrame\n",
    "df_steam_games"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert 'Release_Date' to datetime objects\n",
    "df_steam_games['Release_Date'] = pd.to_datetime(df_steam_games['Release_Date'], dayfirst=True, errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Null columns in 'Release_Date'\n",
    "null_release = df_steam_games['Release_Date'].isnull().sum()\n",
    "print(null_release)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove na from Release_Date\n",
    "df_steam_games.dropna(subset = ['Release_Date'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_steam_games"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add column 'Release_Year' with the year from 'Release_Date'\n",
    "df_steam_games['Release_Year'] = pd.to_datetime(df_steam_games['Release_Date']).dt.year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View DataFrame\n",
    "df_steam_games"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply float_to_string function to 'Genres' column\n",
    "df_steam_games['Genres'] = df_steam_games['Genres'].apply(float_to_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_steam_games"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to check if a value is a string and convert to 0\n",
    "def string_to_zero(value):\n",
    "    if isinstance(value, str):\n",
    "        return 0\n",
    "    else:\n",
    "        return value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check na in 'Price' column\n",
    "df_steam_games['Price'].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete na rows in 'Price' column\n",
    "df_steam_games.dropna(subset= ['Price'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the string_to_zero function in the free to play column\n",
    "df_steam_games['Price'] = df_steam_games['Price'].apply(string_to_zero)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the number of non-numeric rows in the 'Price' column\n",
    "non_numeric_count = pd.to_numeric(df_steam_games['Price'], errors='coerce').isnull().sum()\n",
    "print(f\"Number of rows with non-numeric values in 'Price': {non_numeric_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert 'Price' column to float type\n",
    "df_steam_games['Price'] = df_steam_games['Price'].astype(float)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_steam_games['Early_Access'].info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert objet to bool\n",
    "df_steam_games['Early_Access'] = df_steam_games['Early_Access'].astype(bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count null values in 'Early_Access'\n",
    "null_count = df_steam_games['Early_Access'].isnull().sum()\n",
    "# Print the number of null values in 'Early_Access' column\n",
    "print(\"\\nNumber of null values in 'Early_Access' column:\", null_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check Developer names\n",
    "df_steam_games"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize 'Developer' names\n",
    "df_steam_games['Developer'] = df_steam_games['Developer'].apply(normalize_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Capitalize the first letter of each word in 'Developer' column\n",
    "df_steam_games['Developer'] = df_steam_games['Developer'].str.title()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count null values in 'Developer' column\n",
    "null_count = df_steam_games['Developer'].isnull().sum()\n",
    "# Print the number of null values in 'Developer' column\n",
    "print(\"\\nNumber of null values in 'Developer' column:\", null_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count null values in 'Developer' column\n",
    "null_count = df_steam_games['Id'].isnull().sum()\n",
    "# Print the number of null values in 'Developer' column\n",
    "print(\"\\nNumber of null values in 'Id' column:\", null_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop rows with null values in 'Developer' column\n",
    "df_steam_games.dropna(subset=['Developer'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop rows with null values in 'Developer' column\n",
    "df_steam_games.dropna(subset=['Id'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count null values in 'Developer' column\n",
    "null_count = df_steam_games['Id'].isnull().sum()\n",
    "# Print the number of null values in 'Developer' column\n",
    "print(\"\\nNumber of null values in 'id' column:\", null_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_steam_games"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_steam_games.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# New columns order\n",
    "new_order = ['Id','App_Name','Price','Release_Year','Release_Date','Genres','Early_Access','Specs','Developer', 'Publisher']\n",
    "df_steam_games= df_steam_games[new_order]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_steam_games"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove '[' and ']' characters as well as single quotes from the 'Genres' column\n",
    "df_steam_games['Genres'] = df_steam_games['Genres'].str.replace(r\"[\\[\\]']\", '', regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_steam_games"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the DataFrame to a Parquet file with gzip compression\n",
    "df_steam_games.to_parquet('GZIP/df_steam_games.gzip', compression='gzip')\n",
    "# Save the DataFrame to a CSV file without including the index column\n",
    "df_steam_games.to_csv('CSV/steam_games.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## australian_user_reviews.json etl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a list for the items\n",
    "review = []\n",
    "# Opening json\n",
    "with open('datasets/australian_user_reviews.json', 'r', encoding='utf-8') as usersRevJson:\n",
    "    for line in usersRevJson:\n",
    "        # Append json items to the list\n",
    "        review.append(ast.literal_eval(line))\n",
    "# Close the json file explicitly\n",
    "usersItemJson.close()\n",
    "# Creating a dataframe\n",
    "df_user_rev = pd.DataFrame(review)\n",
    "# Viewing the dataframe\n",
    "df_user_rev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explode data from the 'reviews' column and create new columns\n",
    "allReviews = df_user_rev.explode('reviews') \n",
    "df_user_rev = pd.concat([allReviews.drop(['reviews'], axis=1), allReviews['reviews'].apply(pd.Series)], axis=1)\n",
    "# View Dataframe\n",
    "df_user_rev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the first newly created column and the 'user_url' column\n",
    "df_user_rev = df_user_rev.drop([0, 'user_url'], axis=1)\n",
    "df_user_rev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change the names of the columns\n",
    "df_user_rev = df_user_rev.rename(columns={'user_id': 'User_Id', 'posted': 'Posted', 'item_id': 'Item_Id', 'helpful': 'Helpful', 'recommend': 'Recommend', 'review': 'Review'})\n",
    "df_user_rev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Counting NaN values in the 'User_Id' column\n",
    "nan_count = df_user_rev['User_Id'].isna().sum()\n",
    "print(\"Number of NaN values in User_Id column:\", nan_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count empty values in the 'funny' column\n",
    "empty_count = df_user_rev['funny'].value_counts()['']\n",
    "# Calculate the total percentage of empty values relative to the total number of rows\n",
    "total_rows = len(df_user_rev)\n",
    "empty_percentage = (empty_count / total_rows) * 100\n",
    "# Print the number of empty values in the 'funny' column\n",
    "print(\"Number of empty values in the 'funny' column:\", empty_count)\n",
    "# Print the total percentage of empty values in the 'funny' column\n",
    "print(\"Total percentage of empty values in the 'funny' column: {:.2f}%\".format(empty_percentage))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count empty values in the 'last_edited' column\n",
    "empty_count_last_edited = (df_user_rev['last_edited'] == '').sum()\n",
    "# Calculate the total percentage of empty values in the 'last_edited' column\n",
    "total_rows = len(df_user_rev)\n",
    "empty_percentage_last_edited = (empty_count_last_edited / total_rows) * 100\n",
    "# Print the number of empty values in the 'last_edited' column\n",
    "print(\"Number of empty values in the 'last_edited' column:\", empty_count_last_edited)\n",
    "# Print the total percentage of empty values in the 'last_edited' column\n",
    "print(\"Total percentage of empty values in the 'last_edited' column: {:.2f}%\".format(empty_percentage_last_edited))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the 'funny' and 'last_edited' columns due to having more than 80% NaN values\n",
    "df_user_rev = df_user_rev.drop(columns=['funny', 'last_edited'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count null 'posted'\n",
    "null_in_Posted = df_user_rev['Posted'].isnull().sum()\n",
    "print(\"Val Null 'posted':\", null_in_Posted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop rows with null values in the 'Posted' column\n",
    "df_user_rev.dropna(subset=['Posted'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_user_rev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the text \"Posted\" from the dates in the 'Posted' column\n",
    "df_user_rev['Posted'] = df_user_rev['Posted'].str.replace('Posted ', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_user_rev['Posted']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Format the data in the 'Posted' column to datetime, assigning NaT (Not a Time) to impossible formats\n",
    "df_user_rev['Posted'] = pd.to_datetime(df_user_rev['Posted'], dayfirst=True, errors='coerce')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_user_rev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove rows with NaT (Not a Time) values in the 'Posted' column\n",
    "df_user_rev.dropna(subset=['Posted'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if the format is correct (YYYY-MM-DD)\n",
    "df_user_rev['Posted'] = pd.to_datetime(df_user_rev['Posted']).dt.strftime('%Y-%m-%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_user_rev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a new column 'Year' containing the year extracted from the 'Posted' column\n",
    "df_user_rev['Year'] = pd.to_datetime(df_user_rev['Posted']).dt.year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the count of null values in each column of the DataFrame\n",
    "null_values = df_user_rev.isnull().sum()\n",
    "print(null_values)\n",
    "df_user_rev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the 'Helpful' column from the DataFrame\n",
    "df_user_rev = df_user_rev.drop(columns=['Helpful'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_user_rev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the sentiment analyzer\n",
    "sentiment_analyzer = SentimentIntensityAnalyzer()\n",
    "\n",
    "# Function to assign sentiment scores according to the scale\n",
    "def sentiment_score(text):\n",
    "    if pd.isnull(text) or text == '':\n",
    "        return 1  # Return neutral if it is empty or NaN\n",
    "    elif isinstance(text, str):\n",
    "        sentiment_score = sentiment_analyzer.polarity_scores(text)\n",
    "        sentiment_score = sentiment_score['compound']\n",
    "        if sentiment_score >= -0.05:\n",
    "            return 2  # Good score\n",
    "        elif sentiment_score <= -0.05:\n",
    "            return 0  # Bad score\n",
    "        else:\n",
    "            return 1  # Neutral score\n",
    "    else:\n",
    "        return 1  # Return neutral for non-string values\n",
    "\n",
    "# Convert the 'Review' column to string\n",
    "df_user_rev['Review'] = df_user_rev['Review'].astype(str)\n",
    "# Apply the function get_sentiment_score to the 'Review' column\n",
    "df_user_rev['Sentiment_Score'] = df_user_rev['Review'].apply(sentiment_score)\n",
    "# View the DataFrame\n",
    "df_user_rev\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the 'Review' column from the DataFrame\n",
    "df_user_rev = df_user_rev.drop(columns=['Review'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_user_rev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the DataFrame to a CSV file named 'user_rev.csv' without including the index\n",
    "df_user_rev.to_csv('CSV/user_rev.csv', index=False)\n",
    "# Also will save a PARQUET file too\n",
    "df_user_rev.to_parquet('GZIP/df_user_revs.gzip', compression='gzip')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Year Playtimes new Dataframe creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the first round of cleaned datasets to create new datasets\n",
    "df_steam_games = pd.read_parquet('GZIP/df_steam_games.gzip')\n",
    "user_items = pd.read_parquet('GZIP/user_items.gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Step 1: Group games by release year and genre, and calculate the total playtime per genre in each year\n",
    "grouped_data = user_items.merge(df_steam_games[['Id', 'Release_Year', 'Genres']], \n",
    "                                 left_on='Item_Id', right_on='Id')\\\n",
    "                          .groupby(['Release_Year', 'Genres'])['Playtime_Forever']\\\n",
    "                          .sum()\\\n",
    "                          .reset_index()\n",
    "\n",
    "# Step 2: Create a new DataFrame with columns 'Release_Year', 'Genres', and 'Total_Playtime'\n",
    "hours_per_year = grouped_data.rename(columns={'Playtime_Forever': 'Total_Playtime'})\n",
    "\n",
    "# Display the new dataset\n",
    "hours_per_year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the hours_per_year in the CSV and GZIP folders\n",
    "df_user_rev.to_csv('CSV/hours_per_year.csv', index=False)\n",
    "# Also will save a PARQUET file too\n",
    "df_user_rev.to_parquet('GZIP/dhours_per_year.gzip', compression='gzip')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
